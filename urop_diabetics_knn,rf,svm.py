# -*- coding: utf-8 -*-
"""UROP DIABETICS - KNN,RF,SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hauxh7RGj2TfMqiLDdEm1YeaQ8RvMibq
"""

# Importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf

df=pd.read_csv("/content/insulin_prediction.csv")

df.shape

df.head()

df.info()

df.describe()

sns.countplot(x = 'Outcome',data = df)

# Histogram of each feature
import itertools

col = df.columns[:17]
plt.subplots(figsize = (20, 15))
length = len(col)

for i, j in itertools.zip_longest(col, range(length)):
    plt.subplot((length/2), 3, j + 1)
    plt.subplots_adjust(wspace = 0.1,hspace = 0.5)
    df[i].hist(bins = 20)
    plt.title(i)
plt.show()

sns.pairplot(df,hue="Outcome")

sns.heatmap(df.corr())
plt.show()

df_new=df

df_new[["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI",'target_glucose','Insulin_prescribed']] =df_new[["Glucose",
                                                          "BloodPressure", "SkinThickness", "Insulin", "BMI",'target_glucose','Insulin_prescribed']] .replace(0, np.NaN)

# Count of NaN
df_new.isnull().sum()

# Replacing NaN with mean values
df_new["Glucose"].fillna(df_new["Glucose"].mean(), inplace = True)
df_new["BloodPressure"].fillna(df_new["BloodPressure"].mean(), inplace = True)
df_new["SkinThickness"].fillna(df_new["SkinThickness"].mean(), inplace = True)
df_new["Insulin"].fillna(df_new["Insulin"].mean(), inplace = True)
df_new["BMI"].fillna(df_new["BMI"].mean(), inplace = True)
df_new["target_glucose"].fillna(df_new["target_glucose"].mean(), inplace = True)
df_new["Insulin_prescribed"].fillna(df_new["Insulin_prescribed"].mean(), inplace = True)

df_new.describe()

# Feature scaling using MinMaxScaler
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
df_scaled = sc.fit_transform(df_new)

df_scaled = pd.DataFrame(df_scaled)
df_scaled

X=df_scaled.iloc[:,[0,1,2,3,4,5,6,7,10,11,12,13,14,15]]
Y=df_scaled.iloc[:,16].values

# Splitting X and Y
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42, stratify = df_new['Outcome'] )

# Checking dimensions
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("Y_train shape:", Y_train.shape)
print("Y_test shape:", Y_test.shape)

"""#KNN"""

# Plotting a graph for n_neighbors
from sklearn import metrics
from sklearn.neighbors import KNeighborsClassifier

X_axis = list(range(1, 31))
acc = pd.Series()
x = range(1,31)

for i in list(range(1, 31)):
    knn_model = KNeighborsClassifier(n_neighbors = i)
    knn_model.fit(X_train, Y_train)
    prediction = knn_model.predict(X_test)
    acc = acc.append(pd.Series(metrics.accuracy_score(prediction, Y_test)))
plt.plot(X_axis, acc)
plt.xticks(x)
plt.title("Finding best value for n_estimators")
plt.xlabel("n_estimators")
plt.ylabel("Accuracy")
plt.grid()
plt.show()
print('Highest value: ',acc.values.max())

# K nearest neighbors Algorithm
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 6, metric = 'minkowski', p = 2)
knn.fit(X_train, Y_train)

Y_pred_knn = knn.predict(X_test)

from sklearn.metrics import accuracy_score
accuracy_knn = accuracy_score(Y_test, Y_pred_knn)
print("K Nearest neighbors: " + str(accuracy_knn * 100))

from sklearn.metrics import confusion_matrix
cm= confusion_matrix(Y_test, Y_pred_knn)
print(cm)

from sklearn.metrics import f1_score

"""#SVM"""

X=df_scaled.iloc[:,[0,1,2,3,4,5,6,7,10,11,12,13,14,15]]
Y=df_scaled.iloc[:,16].values

# Splitting X and Y
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20,random_state = 42, stratify = df_new['Outcome'] )

# Support Vector Classifier Algorithm
from sklearn.svm import SVC
svc = SVC(kernel = 'linear', random_state = 2529)
svc.fit(X_train, Y_train)

Y_pred_svc = svc.predict(X_test)
accuracy_svc = accuracy_score(Y_test, Y_pred_svc)
print("Support Vector Classifier: " + str(accuracy_svc * 100))

cm= confusion_matrix(Y_test, Y_pred_svc)
cm

"""#Decision tree"""

X=df_scaled.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,12,13,14,15]]
Y=df_scaled.iloc[:,16].values

# Splitting X and Y
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42, stratify = df_new['Outcome'] )
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
# Decision tree Algorithm
from sklearn.tree import DecisionTreeClassifier
dectree = DecisionTreeClassifier(criterion = 'entropy', random_state = 42)
dectree.fit(X_train, Y_train)

Y_pred_dectree = dectree.predict(X_test)
accuracy_dectree = accuracy_score(Y_test, Y_pred_dectree)
print("Decision tree: " + str(accuracy_dectree * 100))

cm= confusion_matrix(Y_test, Y_pred_dectree)
cm

"""#RANDOM FOREST"""

# Random forest Algorithm
X=df_scaled.iloc[:,[0,1,2,3,4,5,6,7,14,15]]
y=df_scaled.iloc[:,16].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=0)

from sklearn.preprocessing import StandardScaler
scaling_x=StandardScaler()
X_train=scaling_x.fit_transform(X_train)
X_test=scaling_x.transform(X_test)

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(criterion = 'entropy', random_state =42)
rfc.fit(X_train, y_train)
y_pred_ranfor=rfc.predict(X_test)
accuracy_rfc=rfc.score(X_test, y_test)*100
print("Random Forest : " + str(accuracy_rfc))
cm= confusion_matrix(y_test, y_pred_ranfor)
cm

